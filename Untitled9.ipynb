{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP8hTMMEv2ojn+zpI88IHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramakrishna12343/NLP-Assignment/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5JRt8TwS8OGv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from keras.layers import Input, Dense, Dropout, LeakyReLU\n",
        "from keras.models import Model, Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10) # reproduction\n",
        "random_dim = 100\n"
      ],
      "metadata": {
        "id": "8Jmd9O_U8-0t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_minst_data():\n",
        "\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # normalize our inputs to be in the range[-1, 1]\n",
        "\n",
        "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
        "\n",
        "    # convert x_train with a shape of (60000, 28, 28) to (60000, 784)\n",
        "\n",
        "    # so we have 784 columns per row\n",
        "\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "\n",
        "    return (x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "k0DjJasl9d-X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer():\n",
        "\n",
        "    return Adam(learning_rate=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "AclE8sD3-isQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator(optimizer):\n",
        "\n",
        "    generator = Sequential()\n",
        "\n",
        "    generator.add(Dense(256, input_dim=random_dim, \\\n",
        "\n",
        "            kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(512))\n",
        "\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(1024))\n",
        "\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(784, activation='tanh'))\n",
        "\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return generator"
      ],
      "metadata": {
        "id": "_bR0Ro_f_xGD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator(optimizer):\n",
        "\n",
        "    discriminator = Sequential()\n",
        "\n",
        "    discriminator.add(Dense(1024, input_dim=784, \\\n",
        "\n",
        "                kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(512))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(256))\n",
        "\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return discriminator"
      ],
      "metadata": {
        "id": "8-eugCTnAAZE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(epoch,generator,examples=100,dim=(10,10),figsize=(10,10)):\n",
        "  noise=np.random.normal(0,1,size=[examples,random_dim])\n",
        "  generated_images=generator.predict(noise)\n",
        "  generated_images=generated_images.reshape(examples,28,28)\n",
        "  plt.figure(figsize=figsize)\n",
        "  for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(dim[0],dim[1],i+1)\n",
        "    plt.imshow(generated_images[i],interpolation='nearest',cmap='gray_r')\n",
        "    plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig('gan_generated_image_epoch_%d.png'%epoch)"
      ],
      "metadata": {
        "id": "hVpqA2rtAyEY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), \\\n",
        "\n",
        "                          figsize=(10, 10)):\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
        "\n",
        "    generated_images = generator.predict(noise)\n",
        "\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for i in range(generated_images.shape[0]):\n",
        "\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', \\\n",
        "\n",
        "                   cmap='gray_r')\n",
        "\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)"
      ],
      "metadata": {
        "id": "GglwcHKmDENR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs=1, batch_size=128):\n",
        "\n",
        "    #1 Get the training and testing data\n",
        "\n",
        "    x_train, y_train, x_test, y_test = load_minst_data()\n",
        "\n",
        "    # Split the training data into batches of size 128\n",
        "\n",
        "    batch_count = x_train.shape[0] / batch_size\n",
        "\n",
        "    #2. Build our GAN netowrk\n",
        "\n",
        "    adam = get_optimizer()\n",
        "\n",
        "    generator = get_generator(adam)\n",
        "\n",
        "    discriminator = get_discriminator(adam)\n",
        "\n",
        "    gan = get_gan_network(discriminator, random_dim, generator, adam)\n",
        "    for e in range(1, epochs+1):\n",
        "\n",
        "        print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "\n",
        "        for _ in tqdm(range(int(batch_count))):\n",
        "\n",
        "            # 4. Get a random set of input noise and images\n",
        "\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "\n",
        "            image_batch = x_train[np.random.randint(0, x_train.shape[0], \\\n",
        "\n",
        "                                                    size=batch_size)]\n",
        "\n",
        "            # 5. Generate fake MNIST images\n",
        "\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            X = np.concatenate([image_batch, generated_images])\n",
        "\n",
        "            # 6. Labels for generated and real data\n",
        "\n",
        "            y_dis = np.zeros(2*batch_size)\n",
        "\n",
        "            # One-sided label smoothing\n",
        "\n",
        "            y_dis[:batch_size] = 0.9\n",
        "\n",
        "#7. Train discriminator\n",
        "\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            discriminator.train_on_batch(X, y_dis)\n",
        "\n",
        "            #8. Train generator\n",
        "\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "\n",
        "            y_gen = np.ones(batch_size)\n",
        "\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "        if e == 1 or e % 20 == 0:\n",
        "\n",
        "            plot_generated_images(e, generator)\n"
      ],
      "metadata": {
        "id": "2RtU46ASFDy_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(30, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Swx5JrIjFClL",
        "outputId": "59652bcb-8154-4c03-c37a-8227def14123"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_gan_network' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-57f9cef8857f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-9aeae9f6f473>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gan_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_gan_network' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2SVtx9aFQx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}